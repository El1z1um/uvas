{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vz/m4r4czw95s9f09jw_6hwnf840000gn/T/ipykernel_15413/847426599.py:8: DeprecationWarning: `import kerastuner` is deprecated, please use `import keras_tuner`.\n",
      "  from kerastuner.engine.hypermodel import HyperModel\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import models, layers\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers.legacy import Adam\n",
    "from tensorflow.keras.optimizers.legacy import SGD\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from kerastuner.engine.hypermodel import HyperModel\n",
    "from kerastuner.tuners import RandomSearch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2600 images belonging to 4 classes.\n",
      "Found 648 images belonging to 4 classes.\n",
      "Found 814 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "img_height = 150\n",
    "img_width = 150\n",
    "batch_size = 32\n",
    "data_directory = '/Users/baudi/AI/practicas/uvas/data/train_val/'\n",
    "test_data_directory = '/Users/baudi/AI/practicas/uvas/data/test/'\n",
    "validation_split = 0.2\n",
    "seed = 42\n",
    "num_classes = 4\n",
    "\n",
    "# Función personalizada para ajustar el contraste\n",
    "def contrast_adjustment(image, alpha=1.5, beta=0.0):\n",
    "    return np.clip(alpha * image + beta, 0, 255)\n",
    "\n",
    "\n",
    "# Crear un generador de imágenes con Data Augmentation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.1,\n",
    "    zoom_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest',\n",
    "    brightness_range=(0.8, 1.2),  # Ajuste de brillo (0.8 - 1.2)\n",
    "    preprocessing_function=contrast_adjustment,  # Ajuste de contraste\n",
    "    validation_split=validation_split\n",
    ")\n",
    "\n",
    "#Crear un generador de imágenes para el conjunto de validación sin Data Augmentation\n",
    "val_datagen = ImageDataGenerator(rescale=1./255, validation_split=validation_split)\n",
    "\n",
    "# Cargar conjuntos de entrenamiento y validación\n",
    "train_dataset = train_datagen.flow_from_directory(\n",
    "    data_directory,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='sparse',\n",
    "    subset='training',\n",
    "    shuffle=True,\n",
    "    seed=seed\n",
    ")\n",
    "\n",
    "val_dataset = val_datagen.flow_from_directory(\n",
    "    data_directory,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='sparse',\n",
    "    subset='validation',\n",
    "    shuffle=False,\n",
    "    seed=seed\n",
    ")\n",
    "\n",
    "# Crear un generador de imágenes para el conjunto de pruebas sin Data Augmentation\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_dataset = test_datagen.flow_from_directory(\n",
    "    test_data_directory,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='sparse',\n",
    "    shuffle=False,\n",
    "    seed=seed\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MyModel(HyperModel):\n",
    "    def __init__(self, num_classes):\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "    def build(self, hp):\n",
    "        model = models.Sequential()\n",
    "        model.add(layers.Rescaling(1./255, input_shape=(img_height, img_width, 3)))\n",
    "        \n",
    "        for i in range(hp.Int('num_conv_layers', min_value=1, max_value=3)):\n",
    "            model.add(layers.Conv2D(\n",
    "                filters=hp.Choice(f'filters_layer_{i}', values=[16, 32, 64]),\n",
    "                kernel_size=3,\n",
    "                padding='same',\n",
    "                activation='relu'))\n",
    "            model.add(layers.BatchNormalization())  # Capa de Batch Normalization\n",
    "            model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "        \n",
    "        model.add(layers.Flatten())\n",
    "        \n",
    "        for i in range(hp.Int('num_dense_layers', min_value=1, max_value=2)):\n",
    "            model.add(layers.Dense(\n",
    "                units=hp.Choice(f'units_layer_{i}', values=[128, 256]),\n",
    "                activation='relu'))\n",
    "        \n",
    "        model.add(layers.Dense(num_classes, activation='softmax'))\n",
    "\n",
    "        learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "\n",
    "        model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate), \n",
    "                    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "                    metrics=['accuracy'])\n",
    "\n",
    "        return model\n",
    "\n",
    "my_model = MyModel(num_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 10 Complete [00h 02m 44s]\n",
      "val_accuracy: 0.6774691343307495\n",
      "\n",
      "Best val_accuracy So Far: 0.9027777910232544\n",
      "Total elapsed time: 00h 30m 21s\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-07 16:07:56.600180: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82/82 [==============================] - ETA: 0s - loss: 0.0540 - accuracy: 0.9823"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-07 16:08:03.670867: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82/82 [==============================] - 8s 90ms/step - loss: 0.0540 - accuracy: 0.9823 - val_loss: 0.6281 - val_accuracy: 0.8812\n",
      "Epoch 2/20\n",
      "82/82 [==============================] - 7s 87ms/step - loss: 0.0715 - accuracy: 0.9785 - val_loss: 0.3597 - val_accuracy: 0.9290\n",
      "Epoch 3/20\n",
      "82/82 [==============================] - 7s 89ms/step - loss: 0.0756 - accuracy: 0.9758 - val_loss: 1.3080 - val_accuracy: 0.8179\n",
      "Epoch 4/20\n",
      "82/82 [==============================] - 7s 87ms/step - loss: 0.0563 - accuracy: 0.9815 - val_loss: 4.1605 - val_accuracy: 0.6235\n",
      "Epoch 5/20\n",
      "82/82 [==============================] - 7s 87ms/step - loss: 0.0376 - accuracy: 0.9862 - val_loss: 0.9555 - val_accuracy: 0.8657\n",
      "Epoch 6/20\n",
      "82/82 [==============================] - 7s 88ms/step - loss: 0.0761 - accuracy: 0.9765 - val_loss: 0.1132 - val_accuracy: 0.9630\n",
      "Epoch 7/20\n",
      "82/82 [==============================] - 7s 87ms/step - loss: 0.0466 - accuracy: 0.9846 - val_loss: 2.0024 - val_accuracy: 0.8318\n",
      "Epoch 8/20\n",
      "82/82 [==============================] - 7s 87ms/step - loss: 0.0346 - accuracy: 0.9862 - val_loss: 1.0825 - val_accuracy: 0.8472\n",
      "Epoch 9/20\n",
      "82/82 [==============================] - 7s 88ms/step - loss: 0.0681 - accuracy: 0.9804 - val_loss: 2.7244 - val_accuracy: 0.7145\n",
      "Epoch 10/20\n",
      "82/82 [==============================] - 7s 88ms/step - loss: 0.0557 - accuracy: 0.9785 - val_loss: 5.3082 - val_accuracy: 0.5926\n",
      "Epoch 11/20\n",
      "82/82 [==============================] - 7s 87ms/step - loss: 0.0418 - accuracy: 0.9838 - val_loss: 5.2366 - val_accuracy: 0.6281\n",
      "Epoch 12/20\n",
      "82/82 [==============================] - 7s 87ms/step - loss: 0.0352 - accuracy: 0.9896 - val_loss: 0.7526 - val_accuracy: 0.8935\n",
      "Epoch 13/20\n",
      "82/82 [==============================] - 7s 87ms/step - loss: 0.0424 - accuracy: 0.9823 - val_loss: 8.9253 - val_accuracy: 0.5972\n",
      "Epoch 14/20\n",
      "82/82 [==============================] - 7s 87ms/step - loss: 0.0460 - accuracy: 0.9858 - val_loss: 1.2178 - val_accuracy: 0.8673\n",
      "Epoch 15/20\n",
      "82/82 [==============================] - 7s 88ms/step - loss: 0.0299 - accuracy: 0.9912 - val_loss: 1.4823 - val_accuracy: 0.8241\n",
      "Epoch 16/20\n",
      "82/82 [==============================] - 7s 87ms/step - loss: 0.0584 - accuracy: 0.9831 - val_loss: 11.2661 - val_accuracy: 0.4938\n",
      "Epoch 17/20\n",
      "82/82 [==============================] - 7s 87ms/step - loss: 0.0473 - accuracy: 0.9831 - val_loss: 1.9303 - val_accuracy: 0.7762\n",
      "Epoch 18/20\n",
      "82/82 [==============================] - 7s 90ms/step - loss: 0.0430 - accuracy: 0.9815 - val_loss: 7.0558 - val_accuracy: 0.6481\n",
      "Epoch 19/20\n",
      "82/82 [==============================] - 7s 88ms/step - loss: 0.0836 - accuracy: 0.9715 - val_loss: 9.7818 - val_accuracy: 0.4414\n",
      "Epoch 20/20\n",
      "82/82 [==============================] - 7s 87ms/step - loss: 0.0604 - accuracy: 0.9804 - val_loss: 17.8654 - val_accuracy: 0.4954\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 17.8654 - accuracy: 0.4954\n",
      "Validation loss: 17.865352630615234, Validation accuracy: 0.49537038803100586\n"
     ]
    }
   ],
   "source": [
    "tuner = RandomSearch(\n",
    "    my_model,\n",
    "    objective='val_accuracy',\n",
    "    max_trials=10,  # número de modelos para probar\n",
    "    directory='/Users/baudi/AI/practicas/uvas/code/my_dir',\n",
    "    project_name='uvas'\n",
    ")\n",
    "\n",
    "# Búsqueda de hiperparámetros\n",
    "tuner.search(train_dataset, validation_data=val_dataset, epochs=20)\n",
    "\n",
    "# Obtener el mejor modelo\n",
    "best_model = tuner.get_best_models(num_models=1)[0]\n",
    "\n",
    "# Entrenar el mejor modelo con todos los datos\n",
    "history = best_model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=val_dataset,\n",
    "    epochs=20\n",
    ")\n",
    "\n",
    "# Evaluación del modelo\n",
    "val_loss, val_accuracy = best_model.evaluate(val_dataset)\n",
    "print(f'Validation loss: {val_loss}, Validation accuracy: {val_accuracy}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
