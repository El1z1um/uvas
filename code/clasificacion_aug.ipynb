{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers.legacy import Adam\n",
    "from tensorflow.keras.optimizers.legacy import SGD\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3248 files belonging to 4 classes.\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-08 16:06:04.066873: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 6s 45ms/step - loss: 0.7332 - accuracy: 0.7669\n",
      "Epoch 2/20\n",
      "102/102 [==============================] - 5s 43ms/step - loss: 0.2769 - accuracy: 0.9033\n",
      "Epoch 3/20\n",
      "102/102 [==============================] - 5s 43ms/step - loss: 0.1488 - accuracy: 0.9504\n",
      "Epoch 4/20\n",
      "102/102 [==============================] - 5s 44ms/step - loss: 0.1244 - accuracy: 0.9603\n",
      "Epoch 5/20\n",
      "102/102 [==============================] - 5s 44ms/step - loss: 0.0767 - accuracy: 0.9729\n",
      "Epoch 6/20\n",
      "102/102 [==============================] - 5s 43ms/step - loss: 0.0536 - accuracy: 0.9809\n",
      "Epoch 7/20\n",
      "102/102 [==============================] - 5s 42ms/step - loss: 0.0467 - accuracy: 0.9846\n",
      "Epoch 8/20\n",
      "102/102 [==============================] - 5s 42ms/step - loss: 0.0424 - accuracy: 0.9840\n",
      "Epoch 9/20\n",
      "102/102 [==============================] - 5s 44ms/step - loss: 0.0326 - accuracy: 0.9883\n",
      "Epoch 10/20\n",
      "102/102 [==============================] - 5s 47ms/step - loss: 0.0456 - accuracy: 0.9828\n",
      "Epoch 11/20\n",
      "102/102 [==============================] - 5s 43ms/step - loss: 0.0393 - accuracy: 0.9874\n",
      "Epoch 12/20\n",
      "102/102 [==============================] - 5s 45ms/step - loss: 0.0146 - accuracy: 0.9960\n",
      "Epoch 13/20\n",
      "102/102 [==============================] - 5s 44ms/step - loss: 0.0111 - accuracy: 0.9975\n",
      "Epoch 14/20\n",
      "102/102 [==============================] - 5s 42ms/step - loss: 0.0167 - accuracy: 0.9942\n",
      "Epoch 15/20\n",
      "102/102 [==============================] - 5s 44ms/step - loss: 0.0205 - accuracy: 0.9938\n",
      "Epoch 16/20\n",
      "102/102 [==============================] - 5s 42ms/step - loss: 0.0317 - accuracy: 0.9889\n",
      "Epoch 17/20\n",
      "102/102 [==============================] - 5s 42ms/step - loss: 0.0541 - accuracy: 0.9815\n",
      "Epoch 18/20\n",
      "102/102 [==============================] - 5s 43ms/step - loss: 0.0173 - accuracy: 0.9929\n",
      "Epoch 19/20\n",
      "102/102 [==============================] - 5s 43ms/step - loss: 0.0101 - accuracy: 0.9972\n",
      "Epoch 20/20\n",
      "102/102 [==============================] - 5s 44ms/step - loss: 0.0163 - accuracy: 0.9954\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2fb394670>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "\n",
    "# Reemplaza los siguientes directorios por los tuyos\n",
    "train_dirs = ['/Users/baudi/AI/practicas/uvas/data/train_val/']\n",
    "batch_size = 32\n",
    "img_height = 150\n",
    "img_width = 150\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "# Función para aplicar data augmentation a un lote de imágenes\n",
    "def data_augmentation(images, labels):\n",
    "    data_augmentation = tf.keras.Sequential([\n",
    "        tf.keras.layers.experimental.preprocessing.RandomRotation(0.2),\n",
    "        tf.keras.layers.experimental.preprocessing.RandomWidth(0.2),\n",
    "        tf.keras.layers.experimental.preprocessing.RandomHeight(0.2),\n",
    "        tf.keras.layers.experimental.preprocessing.RandomFlip(mode='horizontal'),\n",
    "    ])\n",
    "    return data_augmentation(images), labels\n",
    "\n",
    "# Carga y aumenta las imágenes utilizando tf.data y prefetch\n",
    "train_ds_list = [image_dataset_from_directory(\n",
    "    directory,\n",
    "    label_mode='categorical',\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=batch_size) for directory in train_dirs]\n",
    "\n",
    "train_ds = train_ds_list[0]\n",
    "for ds in train_ds_list[1:]:\n",
    "    train_ds = train_ds.concatenate(ds)\n",
    "\n",
    "train_ds = train_ds.shuffle(1000).map(data_augmentation, num_parallel_calls=AUTOTUNE).prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "# Construye y compila tu CNN aquí\n",
    "model = build_model()\n",
    "# Entrena tu CNN usando la data augmentation\n",
    "model.fit(\n",
    "    train_ds,\n",
    "    epochs=20\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "\n",
    "    model = Sequential([\n",
    "        Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        \n",
    "        Conv2D(64, (3, 3), activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        \n",
    "        Conv2D(128, (3, 3), activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "        Conv2D(256, (3, 3), activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "        Conv2D(512, (3, 3), activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "        Flatten(),\n",
    "        Dense(1024, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.5),\n",
    "        Dense(4, activation='softmax')  # 4 clases: sanas, enfermedad1, enfermedad2, enfermedad3\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer=Adam(learning_rate=0.0001),\n",
    "                loss='categorical_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 814 images belonging to 4 classes.\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 11.2825 - accuracy: 0.2899\n",
      "Test Loss: 11.2825\n",
      "Test Accuracy: 0.2899\n"
     ]
    }
   ],
   "source": [
    "test_data_directory = '/Users/baudi/AI/practicas/uvas/data/test/'\n",
    "\n",
    "# Crear un generador de imágenes para el conjunto de pruebas sin Data Augmentation\n",
    "test_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    ")\n",
    "test_data = test_datagen.flow_from_directory(\n",
    "    test_data_directory,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "# Evaluar el modelo final en los datos de prueba\n",
    "test_loss, test_accuracy = model.evaluate(test_data)\n",
    "print(f'Test Loss: {test_loss:.4f}')\n",
    "print(f'Test Accuracy: {test_accuracy:.4f}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
