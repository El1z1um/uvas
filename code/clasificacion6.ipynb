{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "from tensorflow.keras.layers import Conv2D, BatchNormalization, MaxPooling2D, Flatten, Dense, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.applications import ResNet50, VGG16, VGG19, InceptionResNetV2\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "img_height = 150\n",
    "img_width = 150\n",
    "batch_size = 32\n",
    "data_directory = '/Users/baudi/AI/practicas/uvas/data/train_val/output/'\n",
    "test_data_directory = '/Users/baudi/AI/practicas/uvas/data/test/output/'\n",
    "val_split = 0.2\n",
    "seed = 42\n",
    "num_classes = 4\n",
    "learning_rate = 0.00001\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8000 files belonging to 4 classes.\n",
      "Using 6400 files for training.\n",
      "Found 8000 files belonging to 4 classes.\n",
      "Using 1600 files for validation.\n",
      "Found 2000 files belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def adjustments(image):\n",
    "    image = tf.image.random_brightness(image, 0.2)\n",
    "    image = tf.image.random_contrast(image, 0.9, 1.1)\n",
    "    return image\n",
    "\n",
    "def process_labels(images, labels):\n",
    "    one_hot_labels = tf.one_hot(labels, depth=num_classes)\n",
    "    return images, one_hot_labels\n",
    "\n",
    "train_data_raw = image_dataset_from_directory(\n",
    "    data_directory,\n",
    "    validation_split=val_split,\n",
    "    subset=\"training\",\n",
    "    seed=seed,\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "class_names = train_data_raw.class_names\n",
    "\n",
    "train_data = train_data_raw.map(lambda x, y: (adjustments(x), y)).map(process_labels).cache().prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "\n",
    "val_data = image_dataset_from_directory(\n",
    "    data_directory,\n",
    "    validation_split=val_split,\n",
    "    subset=\"validation\",\n",
    "    seed=seed,\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=batch_size\n",
    ").map(process_labels).cache().prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "test_data = image_dataset_from_directory(\n",
    "    test_data_directory,\n",
    "    seed=seed,\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=batch_size\n",
    ").map(process_labels).cache().prefetch(tf.data.experimental.AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    model = Sequential([\n",
    "        Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(img_height, img_width, 3)),\n",
    "        BatchNormalization(),\n",
    "        Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "        Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "        BatchNormalization(),\n",
    "        Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "        Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "        BatchNormalization(),\n",
    "        Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "        Conv2D(256, (3, 3), activation='relu', padding='same'),\n",
    "        BatchNormalization(),\n",
    "        Conv2D(256, (3, 3), activation='relu', padding='same'),\n",
    "        BatchNormalization(),\n",
    "        Conv2D(256, (3, 3), activation='relu', padding='same'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "        Conv2D(256, (3, 3), activation='relu', padding='same'),\n",
    "        BatchNormalization(),\n",
    "        Conv2D(256, (3, 3), activation='relu', padding='same'),\n",
    "        BatchNormalization(),\n",
    "        Conv2D(256, (3, 3), activation='relu', padding='same'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "        Flatten(),\n",
    "        Dense(512, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.5),\n",
    "        Dense(512, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.5),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate),\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_ResNet50():\n",
    "    base_model = ResNet50(\n",
    "        include_top=False, \n",
    "        input_shape=(img_height, img_width, 3), \n",
    "        weights='imagenet'\n",
    "    )\n",
    "\n",
    "    # Obtener las últimas 10 capas\n",
    "    x = base_model.layers[-10].output\n",
    "\n",
    "    # Agregar las capas densas para la clasificación\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(1024, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    output = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "    # Crear el modelo final\n",
    "    model = Model(inputs=base_model.input, outputs=output)\n",
    "\n",
    "    # Congelar todas las capas de la red base excepto las últimas 10\n",
    "    for layer in base_model.layers[:-10]:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # Compilar el modelo\n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate),\n",
    "                loss='categorical_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_VGG16():\n",
    "    # Cargar la red pre-entrenada VGG16\n",
    "    base_model = VGG16(weights='imagenet', include_top=False, input_shape=(img_height, img_width, 3))\n",
    "    \n",
    "    # Congelar todas las capas de la red base excepto las últimas 10\n",
    "    for layer in base_model.layers[:-10]:\n",
    "        layer.trainable = False\n",
    "        \n",
    "    # Añadir capas adicionales para la clasificación\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(1024, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    output = Dense(num_classes, activation='softmax')(x)\n",
    "    \n",
    "    # Crear el modelo final\n",
    "    model = Model(inputs=base_model.input, outputs=output)\n",
    "    \n",
    "    # Compilar el modelo\n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate),\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_VGG19():\n",
    "    # Cargar la red pre-entrenada VGG19\n",
    "    base_model = VGG19(weights='imagenet', include_top=False, input_shape=(img_height, img_width, 3))\n",
    "    \n",
    "    # Congelar todas las capas de la red base excepto las últimas 12\n",
    "    for layer in base_model.layers[:-12]:\n",
    "        layer.trainable = False\n",
    "        \n",
    "    # Añadir capas adicionales para la clasificación\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(1024, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    output = Dense(num_classes, activation='softmax')(x)\n",
    "    \n",
    "    # Crear el modelo final\n",
    "    model = Model(inputs=base_model.input, outputs=output)\n",
    "    \n",
    "    # Compilar el modelo\n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate),\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_InceptionResNetV2():\n",
    "    # Cargar la red pre-entrenada InceptionResNetV2\n",
    "    base_model = InceptionResNetV2(weights='imagenet', include_top=False, input_shape=(img_height, img_width, 3))\n",
    "\n",
    "    # Congelar todas las capas de la red base excepto las últimas 12\n",
    "    for layer in base_model.layers[:-12]:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # Añadir capas adicionales para la clasificación\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(1024, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    output = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "    # Crear el modelo final\n",
    "    model = Model(inputs=base_model.input, outputs=output)\n",
    "\n",
    "    # Compilar el modelo\n",
    "    model.compile(optimizer=SGD(learning_rate=learning_rate,momentum=0.9),\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def cross_validate(model_builder, n_splits=2, epochs=20):\n",
    "    kfold = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    X = np.concatenate([x for x, y in train_data] + [x for x, y in val_data])\n",
    "    y = np.concatenate([y for x, y in train_data] + [y for x, y in val_data])\n",
    "\n",
    "    accuracies = []\n",
    "    for fold, (train_idx, val_idx) in enumerate(kfold.split(X, y), start=1):\n",
    "        model = model_builder()\n",
    "        print(f\"Comienza el entrenamiento del fold {fold}\")\n",
    "        history = model.fit(X[train_idx],\n",
    "                  y[train_idx],\n",
    "                  validation_data=(X[val_idx], y[val_idx]),\n",
    "                  epochs=epochs)\n",
    "        print(f\"Termina el entrenamiento del fold {fold}\")\n",
    "        val_accuracy = history.history['val_accuracy']\n",
    "        last_val_accuracy = val_accuracy[-1]\n",
    "        print(f\"Precisión de validación del fold {fold}: {last_val_accuracy}\")\n",
    "\n",
    "        accuracies.append(last_val_accuracy)\n",
    "\n",
    "    return np.mean(accuracies)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mean_accuracy = cross_validate(build_model_VGG19,5,20)\n",
    "print(f'Mean accuracy: {mean_accuracy:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-09 23:20:56.340155: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 54s 213ms/step - loss: 1.0292 - accuracy: 0.6094\n",
      "Epoch 2/30\n",
      "250/250 [==============================] - 53s 211ms/step - loss: 0.2052 - accuracy: 0.9321\n",
      "Epoch 3/30\n",
      "250/250 [==============================] - 53s 213ms/step - loss: 0.1023 - accuracy: 0.9658\n",
      "Epoch 4/30\n",
      "250/250 [==============================] - 53s 213ms/step - loss: 0.0499 - accuracy: 0.9835\n",
      "Epoch 5/30\n",
      "250/250 [==============================] - 53s 213ms/step - loss: 0.0501 - accuracy: 0.9850\n",
      "Epoch 6/30\n",
      "250/250 [==============================] - 53s 211ms/step - loss: 0.0187 - accuracy: 0.9950\n",
      "Epoch 7/30\n",
      "250/250 [==============================] - 54s 215ms/step - loss: 0.0316 - accuracy: 0.9896\n",
      "Epoch 8/30\n",
      "250/250 [==============================] - 54s 217ms/step - loss: 0.0166 - accuracy: 0.9954\n",
      "Epoch 9/30\n",
      "250/250 [==============================] - 54s 217ms/step - loss: 0.0089 - accuracy: 0.9974\n",
      "Epoch 10/30\n",
      "250/250 [==============================] - 54s 215ms/step - loss: 0.0156 - accuracy: 0.9956\n",
      "Epoch 11/30\n",
      "250/250 [==============================] - 53s 213ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "Epoch 12/30\n",
      "250/250 [==============================] - 53s 211ms/step - loss: 0.0106 - accuracy: 0.9966\n",
      "Epoch 13/30\n",
      "250/250 [==============================] - 53s 210ms/step - loss: 0.0203 - accuracy: 0.9944\n",
      "Epoch 14/30\n",
      "250/250 [==============================] - 53s 210ms/step - loss: 0.0123 - accuracy: 0.9966\n",
      "Epoch 15/30\n",
      "250/250 [==============================] - 54s 214ms/step - loss: 0.0016 - accuracy: 0.9998\n",
      "Epoch 16/30\n",
      "250/250 [==============================] - 54s 216ms/step - loss: 4.3051e-04 - accuracy: 1.0000\n",
      "Epoch 17/30\n",
      "250/250 [==============================] - 53s 214ms/step - loss: 3.4980e-04 - accuracy: 1.0000\n",
      "Epoch 18/30\n",
      "250/250 [==============================] - 53s 212ms/step - loss: 8.6371e-05 - accuracy: 1.0000\n",
      "Epoch 19/30\n",
      "250/250 [==============================] - 53s 212ms/step - loss: 8.0699e-05 - accuracy: 1.0000\n",
      "Epoch 20/30\n",
      "250/250 [==============================] - 54s 215ms/step - loss: 7.3394e-05 - accuracy: 1.0000\n",
      "Epoch 21/30\n",
      "250/250 [==============================] - 55s 222ms/step - loss: 4.6611e-05 - accuracy: 1.0000\n",
      "Epoch 22/30\n",
      "250/250 [==============================] - 54s 215ms/step - loss: 3.7912e-05 - accuracy: 1.0000\n",
      "Epoch 23/30\n",
      "250/250 [==============================] - 53s 214ms/step - loss: 2.8505e-05 - accuracy: 1.0000\n",
      "Epoch 24/30\n",
      "250/250 [==============================] - 54s 214ms/step - loss: 2.0745e-05 - accuracy: 1.0000\n",
      "Epoch 25/30\n",
      "250/250 [==============================] - 54s 215ms/step - loss: 2.2032e-05 - accuracy: 1.0000\n",
      "Epoch 26/30\n",
      "250/250 [==============================] - 54s 216ms/step - loss: 1.8170e-05 - accuracy: 1.0000\n",
      "Epoch 27/30\n",
      "250/250 [==============================] - 53s 214ms/step - loss: 1.7856e-05 - accuracy: 1.0000\n",
      "Epoch 28/30\n",
      "250/250 [==============================] - 53s 214ms/step - loss: 1.5320e-05 - accuracy: 1.0000\n",
      "Epoch 29/30\n",
      "250/250 [==============================] - 54s 215ms/step - loss: 8.2097e-06 - accuracy: 1.0000\n",
      "Epoch 30/30\n",
      "250/250 [==============================] - 53s 214ms/step - loss: 8.2444e-06 - accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def train_final_model(model_builder, epochs=20):\n",
    "    X = np.concatenate([x for x, y in train_data] + [x for x, y in val_data])\n",
    "    y = np.concatenate([y for x, y in train_data] + [y for x, y in val_data])\n",
    "\n",
    "    final_model = model_builder()\n",
    "\n",
    "    # Definir el callback de EarlyStopping\n",
    "    early_stopping = EarlyStopping(monitor='loss', patience=3, min_delta=0.001)\n",
    "\n",
    "    # Agregar el callback al método fit\n",
    "    final_model.fit(X, y, epochs=epochs)\n",
    "\n",
    "    return final_model\n",
    "\n",
    "final_model = train_final_model(build_model_VGG19,30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 7s 107ms/step - loss: 0.1396 - accuracy: 0.9770\n",
      "Test Loss: 0.1396\n",
      "Test Accuracy: 0.9770\n",
      "63/63 [==============================] - 7s 106ms/step\n",
      "Classification Report:\n",
      "                                            precision    recall  f1-score   support\n",
      "\n",
      "                         Grape___Black_rot       0.95      0.97      0.96       565\n",
      "              Grape___Esca_(Black_Measles)       0.97      0.97      0.97       670\n",
      "Grape___Leaf_blight_(Isariopsis_Leaf_Spot)       1.00      0.99      1.00       547\n",
      "                           Grape___healthy       1.00      1.00      1.00       218\n",
      "\n",
      "                                  accuracy                           0.98      2000\n",
      "                                 macro avg       0.98      0.98      0.98      2000\n",
      "                              weighted avg       0.98      0.98      0.98      2000\n",
      "\n",
      "Confusion Matrix:\n",
      "[[546  18   1   0]\n",
      " [ 23 647   0   0]\n",
      " [  3   0 544   0]\n",
      " [  1   0   0 217]]\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = final_model.evaluate(test_data)\n",
    "print(f'Test Loss: {test_loss:.4f}')\n",
    "print(f'Test Accuracy: {test_accuracy:.4f}')\n",
    "\n",
    "Y_pred = final_model.predict(test_data)\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "\n",
    "y_true = np.concatenate([y.numpy() for _, y in test_data.unbatch()])\n",
    "y_true_labels = np.argmax(y_true.reshape(-1, len(class_names)), axis=1)\n",
    "\n",
    "print('Classification Report:')\n",
    "print(classification_report(y_true_labels, y_pred, target_names=class_names))\n",
    "\n",
    "print('Confusion Matrix:')\n",
    "print(confusion_matrix(y_true_labels, y_pred))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
